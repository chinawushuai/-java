散列表一(Hash Table)

1、散列思想：

散列表用的是数组支持下按照下标随机访问数据的特性，散列表是数组的一种拓展，由数组演化而来。时间复杂度为O(1)。

2、散列函数（Hash函数、哈希函数）
通过散列函数计算得到的值称为散列值（哈希值、Hash值）：hash(key)

散列函数设计的基本要求：
1）散列函数计算得到的值是一个非负整数
2）如果key1==key2,那hash(key1)==hash(key2)
3）如果key1!=key2,那hash(key1)!=hash(key2)

3、散列冲突：
装载因子=填入表中的元素个数/散列表的长度
ps：散列表长度要尽可能选择素数
1）开放寻址法：
线性探测：hash(key)+k最坏情况下时间复杂度为O(n)
二次探测法：hash(key)+k2
双重散列：使用一组哈希函数
2）拉链法：
插入的时间复杂度：O(1)
查找和删除的时间复杂度为：O(k),k=n/m,n表示散列表中数据的个数，m表示散列表中槽的个数。

散列表二（Hash Table）

1、如何设计散列函数：
1）散列函数不能太复杂
2）散列函数生成的值要尽可能随机并且均匀分布

2、装载因子过大怎么办：
1）动态扩容
2）避免低效扩容：将扩容操作穿插在插入操作的过程中，分批完成，当装载因子因子抵达阈值之后，我们只申请新空间，
   但是并不讲老的数据搬移到新散列表中，当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中
   拿出一个数据放到新的散列表中
   
3、如何选择冲突解决方法：
1）开放寻址法：优点：数据存储在数组中，可以有效利用CPU缓存加快查询速度，序列化比较简单
            缺点：删除数据比较麻烦，需要特殊标记已经删除掉的数据，所有数据都存储在一个数组中，比起链表法来说，冲突的代价更高，装填因子上限不能太大
                 也导致比链表法更浪费空间
            总结：当数据量较小，装填因子小的时候，适合采用开放寻址法。例如：java中的ThreadLocalMap使用开放寻址法解决散列冲突
2）链表法：优点：对内存的利用率比开放寻址法要高，链表节点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好，对装填因子的容忍度更高
          缺点：链表需要存储指针，对于比较小的对象的存储比较消耗内存，链表中的节点是零散分布在内存中的，不是连续的，所以对cpu缓存不友好，
                对执行效率有一定影响
          改进：当我们的存储对象是大对象，也就是说存储的对象大小远远大于一个指针的大小（4个字节或者8个字节），
               那链表中指针的内存消耗在大对象面前就可以忽略了，将链表法中的链表改造成其他高效的动态数据结构，比如跳表、红黑树，
               查询的时间复杂度为O(logn),可以有效避免散列碰撞攻击
          总结：适合大对象、大数据量的散列表，比起开放寻址法，它更加灵活，支持更多的优化策略，比如使用红黑树代替链表
          
4、工业级散列表举例分析（HashMap）
1）初始大小：HashMap默认初始大小是16，可以设置
2）装载因子和动态扩容：装载因子默认是0.75，每次扩容为原来两倍
3）散列冲突解决方法：HashMap底层采用链表法来解决冲突，JDK1.8，对HashMap做了优化，引入红黑树，当红黑树节点小于8个的时候，又会将红黑树转化为链表
4）散列函数：设计并不复杂，追求简单高效、分布均匀。

散列表三（Hash Table）
散列表和链表为何经常放在一起使用？

1、LRU缓存淘汰算法：借助散列表可以将LRU缓存淘汰算法的时间复杂度降低为O(1)
缓存系统主要包含的操作：
1）往缓存中添加一个数据
2）从缓存中删除一个数据
3）在缓存中查找一个数据
这三个操作都设计“查找”操作，如果单纯使用链表，时间复杂度为O(n)，如果将散列表和链表两种数据结构组合使用，就可以将这三个操作的时间复杂度
降低到O(1)
解决方法：使用双向链表存储数据，链表中的每个结点除了存储数据（data）、前驱指针（prev）、后继指针（next）之外，还增添了一个特殊字段hnext，是为了将结点
串在散列表的拉链中

2、Redis有序集合
操作：
1）添加一个成员对象
2）按照键值来删除一个成员对象
3）按照键值来查找一个成员对象
4）按照分值区间查找数据，比如查找积分在[100，356]之间的成员对象
5）按照分值从小到大排序成员变量
解决方法：按照键值构建一个散列表，这样按照key值来删除、查找一个成员对象的时间复杂度就变成O(1)，同时借助跳表结构，其他操作也非常高效。

3、Java LinkedHashMap
LinkedHashMap本身就是一个支持LRU缓存淘汰策略的缓存系统，LinkedHashMap

